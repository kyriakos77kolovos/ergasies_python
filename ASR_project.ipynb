{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "history_visible": true,
      "mount_file_id": "1whWmXWOYU7Qju9rPFzbjYIezR7JbyhlB",
      "authorship_tag": "ABX9TyPBTbU8zJMeItZH5siJ+Nld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyriakos77kolovos/ergasies_python/blob/master/ASR_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_utilities.py"
      ],
      "metadata": {
        "id": "YKnHxO8vzqZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from librosa import resample, stft, magphase, amplitude_to_db\n",
        "from librosa.feature import melspectrogram\n",
        "from pathlib import Path\n",
        "from pickle import load, dump\n",
        "from warnings import filterwarnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from pandas import DataFrame, read_csv\n",
        "from seaborn import heatmap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow._api.v2.math import confusion_matrix\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.python.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.python.keras.models import Sequential, load_model\n",
        "\n",
        "#from Utilities.Constants import PATH_OF_SAVED_MODEL, PATH_OF_SAVED_LABELS, PATH_OF_SAVED_MODEL_HISTORY\n",
        "#from Utilities.load_files import loadTrainedData\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def loadModel(model_path: Path):\n",
        "    model = load_model(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def saveModel(model: Sequential, model_path: Path):\n",
        "    model.save(model_path)\n",
        "\n",
        "\n",
        "def loadHistory(model_history_path: Path):\n",
        "    model_history = read_csv(model_history_path)\n",
        "    return model_history\n",
        "\n",
        "\n",
        "def saveHistory(history: DataFrame, model_history_path: Path):\n",
        "    history.to_csv(model_history_path)\n",
        "\n",
        "\n",
        "def loadLabelEncoder(labels_path: Path):\n",
        "    label_encoder = load(open(labels_path, 'rb'))\n",
        "    return label_encoder\n",
        "\n",
        "\n",
        "def saveLabelEncoder(label_encoder: LabelEncoder, labels_path: Path):\n",
        "    dump(label_encoder, open(labels_path, 'wb'))\n",
        "\n",
        "\n",
        "def createModel(x_train: np.array, classes_count):\n",
        "    input_shape = (x_train.shape[1], x_train.shape[2])\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Adding Layers\n",
        "    # 1st LSTM layer\n",
        "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    # 2nd LSTM layer\n",
        "    model.add(LSTM(64))\n",
        "\n",
        "    # 1st Dense layer\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Outputs\n",
        "    model.add(Dense(classes_count, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def initCallbacks():\n",
        "    es = EarlyStopping(monitor='val_loss',\n",
        "                       mode='min',\n",
        "                       patience=6,\n",
        "                       min_delta=0.0001)\n",
        "\n",
        "    mc = ModelCheckpoint('best_model.hdf5',\n",
        "                         monitor='val_acc',\n",
        "                         save_best_only=True,\n",
        "                         mode='max')\n",
        "    return es, mc\n",
        "\n",
        "\n",
        "def splitDataset(mel_trained_data: np.array, y: np.array):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(mel_trained_data,\n",
        "                                                        np.array(y),\n",
        "                                                        stratify=y,\n",
        "                                                        test_size=0.2,\n",
        "                                                        shuffle=True)\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
        "                                                      test_size=0.2)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    x_test = np.array(x_test)\n",
        "    x_val = np.array(x_val)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "    y_val = np.array(y_val)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test, x_val, y_val\n",
        "\n",
        "\n",
        "def modelEvaluation(model: Sequential, x_train, y_train, x_test, y_test):\n",
        "    train_score = model.evaluate(x_train, y_train, batch_size=32)\n",
        "    test_score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "\n",
        "    print(\"Train score: {}\".format(train_score))\n",
        "    print(\"Test score: {}\".format(test_score))\n",
        "\n",
        "\n",
        "def displayModelPlot(history_dict: DataFrame):\n",
        "    loss_values = history_dict['loss']\n",
        "    acc_values = history_dict['accuracy']\n",
        "    val_loss_values = history_dict['val_loss']\n",
        "    val_acc_values = history_dict['val_accuracy']\n",
        "    epochs = range(1, len(loss_values) + 1)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    ax1.plot(epochs, loss_values, 'co', label='Training Loss')\n",
        "    ax1.plot(epochs, val_loss_values, 'm', label='Validation Loss')\n",
        "    ax1.set_title('Training and validation loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax2.plot(epochs, acc_values, 'co', label='Training accuracy')\n",
        "    ax2.plot(epochs, val_acc_values, 'm', label='Validation accuracy')\n",
        "    ax2.set_title('Training and validation accuracy')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def displayConfusionMatrix(model: Sequential, x_test, y_test, classes):\n",
        "    y_predict = model.predict(x_test)\n",
        "    conf_mat = confusion_matrix(np.argmax(y_test, axis=1),\n",
        "                                np.argmax(y_predict, axis=1))\n",
        "\n",
        "    df_cm = DataFrame(np.array(conf_mat), index=[i for i in classes],\n",
        "                         columns=[i for i in classes])\n",
        "    plt.figure(figsize=(13, 7))\n",
        "    ax = heatmap(df_cm, annot=True)\n",
        "    plt.title(\"Confusion Matrix\", fontsize=20)\n",
        "    plt.ylabel(\"True Class\", fontsize=20)\n",
        "    plt.xlabel(\"Predicted Class\", fontsize=20)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def createModels():\n",
        "    y, classes = None, None\n",
        "    model_path = Path(\"/drive/MyDrive/ASR/ASR_Project-main/\")\n",
        "    model_history_path = Path(\"/drive/MyDrive/ASR/ASR_Project-main/\")\n",
        "    labels_path = Path(\"/drive/MyDrive/ASR/ASR_Project-main/\")\n",
        "\n",
        "    TRAIN_DATA_PATH_FLAG_EXISTS, mel_trained_data, labels = loadTrainedData()\n",
        "    model, model_history, label_encoder = None, None, None\n",
        "    if model_path.exists():\n",
        "        model = loadModel(model_path)\n",
        "\n",
        "    if labels_path.exists():\n",
        "        label_encoder = loadLabelEncoder(labels_path)\n",
        "        y = label_encoder.fit_transform(labels)\n",
        "        classes = list(label_encoder.classes_)\n",
        "        classes_count = len(classes)\n",
        "        y = np_utils.to_categorical(y, num_classes=classes_count, dtype='float32')\n",
        "\n",
        "    if TRAIN_DATA_PATH_FLAG_EXISTS:\n",
        "        x_train, x_test, y_train, y_test, x_val, y_val = splitDataset(mel_trained_data, y)\n",
        "    else:\n",
        "        return model, label_encoder\n",
        "\n",
        "    if model_history_path.exists() and TRAIN_DATA_PATH_FLAG_EXISTS:\n",
        "        model_history = loadHistory(model_history_path)\n",
        "        displayModelPlot(model_history)\n",
        "        displayConfusionMatrix(model, x_test, y_test, classes)\n",
        "\n",
        "    if model is None or label_encoder is None:\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        y = label_encoder.fit_transform(labels)\n",
        "        classes = list(label_encoder.classes_)\n",
        "        classes_count = len(classes)\n",
        "        y = np_utils.to_categorical(y, num_classes=classes_count, dtype='float32')\n",
        "\n",
        "        saveLabelEncoder(label_encoder, labels_path)\n",
        "\n",
        "        if TRAIN_DATA_PATH_FLAG_EXISTS:\n",
        "            x_train, x_test, y_train, y_test, x_val, y_val = splitDataset(mel_trained_data, y)\n",
        "        else:\n",
        "            return None, None\n",
        "\n",
        "        model = createModel(np.array(x_train), classes_count)\n",
        "        model.summary()\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        es, mc = initCallbacks()\n",
        "\n",
        "        model_history = model.fit(x_train, y_train,\n",
        "                                  validation_data=(x_val, y_val),\n",
        "                                  epochs=100, callbacks=[es, mc],\n",
        "                                  batch_size=64)\n",
        "        model_history = model_history.history\n",
        "        saveModel(model, model_path)\n",
        "        saveHistory(model_history, model_history_path)\n",
        "        displayModelPlot(model_history)\n",
        "        modelEvaluation(model, x_train, y_train, x_test, y_test)\n",
        "        displayConfusionMatrix(model, x_test, y_test, classes)\n",
        "\n",
        "    return model, label_encoder\n",
        "\n",
        "\n",
        "def predictDigit(model: Sequential, classes, signal: np.array):\n",
        "    prob = model.predict(signal)\n",
        "    index = np.argmax(prob[0])\n",
        "    return classes[index]\n",
        "\n",
        "\n",
        "def loadTrainedData():\n",
        "        return True, None, None"
      ],
      "metadata": {
        "id": "1qYIjiPUzvjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "requirements.txt"
      ],
      "metadata": {
        "id": "Dm0YUI3M0wDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install seaborn~=0.11.2"
      ],
      "metadata": {
        "id": "vseT2Ftk0y42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}